{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "In this project, I'll work with a data set of submissions to popular technology site [Hacker News](https://news.ycombinator.com/).\n",
    "\n",
    "Hacker News is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "I'm specifically interested in posts whose titles begin with either **Ask HN** or **Show HN**. Users submit Ask HN posts to ask the Hacker News community a specific question; Users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "I'll compare these two types of posts to determine the following:\n",
    "\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "## Opening and Exploring the Data\n",
    "\n",
    "I'll start by opening and reading the data set so that I can begin managing/manipulating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open(\"../data_sets/hacker_news.csv\")\n",
    "read_file = reader(opened_file)\n",
    "\n",
    "hn = list(read_file)\n",
    "hn_header = hn[0]\n",
    "hn = hn[1:] # Exclude the header row (column names) from the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to make the data set easier to explore, I'll create a function named `explore_data()` that I can repeatedly use to print rows of data in a readable way. In addition, when I use this function, I'll have the option to output the number of rows and columns in the data set. After I define this function, I'll print the columns (header row) of the data set to understand what each data point represents. Lastly, I'll use the function to investigate a small selection of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "Number of rows: 293119\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "def explore_data(data_set, start, end, rows_and_columns=False):\n",
    "    data_slice = data_set[start:end]\n",
    "    for row in data_slice:\n",
    "        print(row)\n",
    "        \n",
    "        # Print an extra line of space after each row for readability\n",
    "        print()\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print(\"Number of rows:\", len(data_set))\n",
    "        print(\"Number of columns:\", len(data_set[0]))\n",
    "        \n",
    "print(hn_header)\n",
    "\n",
    "print()\n",
    "\n",
    "explore_data(hn, 0, 3, True) # First few rows of the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "- `id`: The unique identifier from Hacker News for the post\n",
    "\n",
    "\n",
    "- `title`: The title of the post\n",
    "\n",
    "\n",
    "- `url`: The URL that the posts links to (if the post has a URL)\n",
    "\n",
    "\n",
    "- `num_points`: The number of points the post acquired (the total number of upvotes minus the total number of downvotes)\n",
    "\n",
    "\n",
    "- `num_comments`: The number of comments that were made on the post\n",
    "\n",
    "\n",
    "- `author`: The username of the person who submitted the post\n",
    "\n",
    "\n",
    "- `created_at`: The date and time at which the post was submitted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
