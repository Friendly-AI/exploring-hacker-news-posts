{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "In this project, I'll work with a data set of submissions to popular technology site [Hacker News](https://news.ycombinator.com/).\n",
    "\n",
    "Hacker News is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "I'm specifically interested in posts whose titles begin with either **Ask HN** or **Show HN**. Users submit Ask HN posts to ask the Hacker News community a specific question; Users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "I'll compare these two types of posts to determine the following:\n",
    "\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "## Opening and Exploring the Data\n",
    "\n",
    "I'll start by opening and reading the data set so that I can begin managing/manipulating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open(\"../data_sets/hacker_news.csv\")\n",
    "read_file = reader(opened_file)\n",
    "\n",
    "hn = list(read_file)\n",
    "hn_header = hn[0] # Contains just the column headers (names)\n",
    "hn = hn[1:] # The data set cannot be analyzed with the header row in the way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to make the data set easier to explore, I'll create a function named `explore_data()` that I can repeatedly use to print rows of data in a readable way. In addition, when I use this function, I'll have the option to output the number of rows and columns in the data set. After I define this function, I'll print the columns (header row) of the data set to understand what each data point represents. Lastly, I'll use the function to investigate a small selection of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "Number of rows: 293119\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "def explore_data(data_set, start, end, rows_and_columns=False):\n",
    "    data_slice = data_set[start:end]\n",
    "    for row in data_slice:\n",
    "        print(row)\n",
    "        \n",
    "        # Print an extra line of space after each row for readability\n",
    "        print()\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print(\"Number of rows:\", len(data_set))\n",
    "        print(\"Number of columns:\", len(data_set[0]))\n",
    "        \n",
    "print(hn_header)\n",
    "\n",
    "print()\n",
    "\n",
    "explore_data(hn, 0, 3, True) # First few rows of the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "- `id`: The unique identifier from Hacker News for the post\n",
    "\n",
    "\n",
    "- `title`: The title of the post\n",
    "\n",
    "\n",
    "- `url`: The URL that the posts links to (if the post has a URL)\n",
    "\n",
    "\n",
    "- `num_points`: The number of points the post acquired (the total number of upvotes minus the total number of downvotes)\n",
    "\n",
    "\n",
    "- `num_comments`: The number of comments that were made on the post\n",
    "\n",
    "\n",
    "- `author`: The username of the person who submitted the post\n",
    "\n",
    "\n",
    "- `created_at`: The date and time at which the post was submitted\n",
    "\n",
    "## Extracting Ask HN and Show HN Posts\n",
    "\n",
    "Now, I'm ready to filter the data. Since I'm only concerned with post titles beginning with Ask HN or Show HN, I'll create sub data sets containing just the data for those titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    \n",
    "    if title.startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN and Show HN Posts\n",
    "\n",
    "With the Ask HN, Show HN, and other posts separated, I'll explore the first five rows of each list to get a good sense of them and find out exactly how many posts are in each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN Posts:\n",
      "\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "\n",
      "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
      "\n",
      "['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57']\n",
      "\n",
      "['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48']\n",
      "\n",
      "['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']\n",
      "\n",
      "Number of rows: 9139\n",
      "Number of columns: 7\n",
      "\n",
      "Show HN Posts:\n",
      "\n",
      "['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36']\n",
      "\n",
      "['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01']\n",
      "\n",
      "['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44']\n",
      "\n",
      "['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17']\n",
      "\n",
      "['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']\n",
      "\n",
      "Number of rows: 10158\n",
      "Number of columns: 7\n",
      "\n",
      "Other Posts:\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
      "\n",
      "Number of rows: 273822\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Ask HN Posts:\\n\")\n",
    "\n",
    "explore_data(ask_posts, 0, 5, True)\n",
    "\n",
    "print(\"\\nShow HN Posts:\\n\")\n",
    "\n",
    "explore_data(show_posts, 0, 5, True)\n",
    "\n",
    "print(\"\\nOther Posts:\\n\")\n",
    "\n",
    "explore_data(other_posts, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ask HN comments per post: 10\n",
      "Average Show HN comments per post: 5\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    \n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    \n",
    "    total_show_comments += num_comments\n",
    "\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print(\"Average Ask HN comments per post:\", round(avg_ask_comments))\n",
    "print(\"Average Show HN comments per post:\", round(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the output above, Ask HN posts receive more comments on average by five, while Show HN posts only receive five comments.\n",
    "\n",
    "Since ask posts are more likely to receive comments, I'll focus my remaining analysis just on these posts.\n",
    "\n",
    "## Finding the Amount of Ask Posts and Comments by Hour Created\n",
    "\n",
    "Next, I'll determine if ask posts created at a certain time are more likely to attract comments. I'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "In this section, I'll tackle the first step — calculating the amount of ask posts and comments by hour created. I'll work with the data in the `created_at` column; I'll calculate the amount of ask posts created per hour, along with the total amount of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    n_comments = int(row[4])\n",
    "    \n",
    "    result_list.append([created_at, n_comments])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    date = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    hour = date.strftime(\"%H\")\n",
    "    n_comments = row[1]\n",
    "    \n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = n_comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += n_comments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
